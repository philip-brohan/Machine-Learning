
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Generating video diagnostics &#8212; Machine Learning Experiments</title>
    <link rel="stylesheet" href="../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="The ML_Utilities package: Functions for data loading and normalisation" href="../../package/ML_Utilities.html" />
    <link rel="prev" title="Simple autoencoder with leaky relu activation (rather than tanh)" href="../activations/leaky_relu/autoencoder.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../package/ML_Utilities.html" title="The ML_Utilities package: Functions for data loading and normalisation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../activations/leaky_relu/autoencoder.html" title="Simple autoencoder with leaky relu activation (rather than tanh)"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">ML Experiments</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../perturbations.html" accesskey="U">Perturbing the simple autoencoder</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/Weather-Network.png" alt="Logo"/>
            </a></p>
<h3><a href="../../index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../prepare_data/prepare_data.html">Getting climate data into TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../simple_autoencoder/autoencoder.html">Getting started - a simple autoencoder</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../perturbations.html">Perturbing the simple autoencoder</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../package/ML_Utilities.html">ML Utilities package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../credits.html">Small Print</a></li>
</ul>
<h3><a href="https://github.com/philip-brohan/Machine-Learning">Get the source code</a></h3>

<a href="https://github.com/philip-brohan/Machine-Learning"
           rel="nofollow">Github source repository</a>

<h3>Found a bug, or have a suggestion?</h3>

Please <a href="https://github.com/philip-brohan/Machine-Learning/issues/new">raise an issue</a>.
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="generating-video-diagnostics">
<h1>Generating video diagnostics<a class="headerlink" href="#generating-video-diagnostics" title="Permalink to this headline">¶</a></h1>
<p>The <a class="reference internal" href="../../simple_autoencoder/summary.html"><span class="doc">simple autoencoder summary plot</span></a> gives a nice representation of the model state and output quality after training. I’d like to show the same representation, as it varies through training, as a video.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<center>
<table><tr><td><center>
<iframe src="https://player.vimeo.com/video/338277430?title=0&byline=0&portrait=0" width="795" height="448" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></center></td></tr>
<tr><td><center>Autencoder model state (left) validation (right)</center></td></tr>
</table>
</center><p>On the left, the model weights: The boxplot in the centre shows the weights associated with each neuron in the hidden layer, arranged in order, largest to smallest. Negative weights have been converted to positive (and the sign of the associated output layer weights switched accordingly). The colourmaps on top are the weights, for each hidden layer neuron, for each input field location (so a lat:lon map). They are aranged in the same order as the hidden layer weights (so if hidden-layer neuron 3 has the largest weight, the input layer weights for neuron 3 are shown at top left). The colourmaps on the bottom are the output layer weights, arranged in the same way.</p>
<p>Top right, a sample pressure field: Original in red, after passing through the autoencoder in blue.</p>
<p>Bottom right, training progress: Loss v. no. of training epochs.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>That means saving the model state after each epoch, and having more, shorter epochs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>

<span class="c1"># Very simple autoencoder for 20CR prmsl fields.</span>
<span class="c1"># Single, fully-connected layer as encoder+decoder, 32 neurons.</span>
<span class="c1"># Very unlikely to work well at all, but this isn&#39;t about good</span>
<span class="c1">#  results, it&#39;s about getting started. </span>
<span class="c1">#</span>
<span class="c1"># This version concentrates on tracking the training of the autoencoder</span>
<span class="c1">#  so small batches/epochs and save the state at every point.</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1">#tf.enable_eager_execution()</span>
<span class="kn">from</span> <span class="nn">tensorflow.data</span> <span class="k">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="k">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># How much to do between output points</span>
<span class="n">epoch_size</span><span class="o">=</span><span class="mi">100</span>
<span class="c1"># How much training in total</span>
<span class="n">n_epochs</span><span class="o">=</span><span class="mi">1000</span>

<span class="c1"># File names for the serialised tensors to train on</span>
<span class="n">input_file_dir</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/Machine-Learning-experiments/datasets/20CR2c/prmsl/training/&quot;</span> <span class="o">%</span>
                   <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;SCRATCH&#39;</span><span class="p">))</span>
<span class="n">training_files</span><span class="o">=</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/*.tfd&quot;</span> <span class="o">%</span> <span class="n">input_file_dir</span><span class="p">)</span>
<span class="n">n_tf</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">training_files</span><span class="p">)</span>
<span class="n">train_tfd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">training_files</span><span class="p">)</span>

<span class="c1"># Create TensorFlow Dataset object from the file names</span>
<span class="n">tr_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">train_tfd</span><span class="p">)</span>

<span class="c1"># Repeat the input data enough times that we don&#39;t run out </span>
<span class="n">n_reps</span><span class="o">=</span><span class="p">(</span><span class="n">epoch_size</span><span class="o">*</span><span class="n">n_epochs</span><span class="p">)</span><span class="o">//</span><span class="n">n_tf</span> <span class="o">+</span><span class="mi">1</span>
<span class="n">tr_data</span> <span class="o">=</span> <span class="n">tr_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">n_reps</span><span class="p">)</span>

<span class="c1"># We don&#39;t want the file names, we want their contents, so</span>
<span class="c1">#  add a map to convert from names to contents.</span>
<span class="k">def</span> <span class="nf">load_tensor</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
    <span class="n">sict</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span> <span class="c1"># serialised</span>
    <span class="n">ict</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">parse_tensor</span><span class="p">(</span><span class="n">sict</span><span class="p">,</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ict</span>
<span class="n">tr_data</span> <span class="o">=</span> <span class="n">tr_data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">load_tensor</span><span class="p">)</span>

<span class="c1"># Also need to reshape the data to linear, and produce a tuple</span>
<span class="c1">#  (source,target) for model</span>
<span class="k">def</span> <span class="nf">to_model</span><span class="p">(</span><span class="n">ict</span><span class="p">):</span>
   <span class="n">ict</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ict</span><span class="p">,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">91</span><span class="o">*</span><span class="mi">180</span><span class="p">])</span>
   <span class="k">return</span><span class="p">(</span><span class="n">ict</span><span class="p">,</span><span class="n">ict</span><span class="p">)</span>
<span class="n">tr_data</span> <span class="o">=</span> <span class="n">tr_data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">to_model</span><span class="p">)</span>

<span class="c1"># Input placeholder - treat data as 1d</span>
<span class="n">original</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">91</span><span class="o">*</span><span class="mi">180</span><span class="p">,))</span>
<span class="c1"># Encoding layer 32-neuron fully-connected</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)(</span><span class="n">original</span><span class="p">)</span>
<span class="c1"># Output layer - same shape as input</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">91</span><span class="o">*</span><span class="mi">180</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>

<span class="c1"># Model relating original to output</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">decoded</span><span class="p">)</span>
<span class="c1"># Choose a loss metric to minimise (RMS)</span>
<span class="c1">#  and an optimiser to use (adadelta)</span>
<span class="n">autoencoder</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adadelta&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>

<span class="c1"># Set up a callback to save the model state</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/Machine-Learning-experiments/&quot;</span><span class="o">+</span>
                <span class="s2">&quot;simple_autoencoder_instrumented/&quot;</span><span class="o">+</span>
                <span class="s2">&quot;saved_models/Epoch_</span><span class="si">{epoch:04d}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;SCRATCH&#39;</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">))</span>
<span class="n">cp_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> 
                                                 <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                 <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train the autoencoder - saving it every epoch</span>
<span class="n">history</span><span class="o">=</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">tr_data</span><span class="p">,</span> <span class="c1"># Get (source,target) pairs from this Dataset</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">epoch_size</span><span class="p">,</span>
                        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp_callback</span><span class="p">],</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># One line per epoch</span>

<span class="c1"># Save the training history</span>
<span class="n">history_file</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/Machine-Learning-experiments/&quot;</span><span class="o">+</span>
              <span class="s2">&quot;simple_autoencoder_instrumented/&quot;</span><span class="o">+</span>
              <span class="s2">&quot;saved_models/history_to_</span><span class="si">%04d</span><span class="s2">.pkl&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span>
                 <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;SCRATCH&#39;</span><span class="p">),</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="n">history_file</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../package/ML_Utilities.html" title="The ML_Utilities package: Functions for data loading and normalisation"
             >next</a> |</li>
        <li class="right" >
          <a href="../activations/leaky_relu/autoencoder.html" title="Simple autoencoder with leaky relu activation (rather than tanh)"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">ML Experiments</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../perturbations.html" >Perturbing the simple autoencoder</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    </div>
  </body>
</html>